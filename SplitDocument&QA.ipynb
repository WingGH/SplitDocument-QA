{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-documentintelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader, PdfWriter  # For splitting the PDF\n",
    "import requests\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest, ContentFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endpoints and Key Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Azure Document Intelligence\n",
    "AZURE_ENDPOINT = \"\" #Document Intelligence Endpoint\n",
    "AZURE_KEY = \"\" #Key for the Document Intelligence Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for OpenAI API\n",
    "OPENAI_API_KEY = \"\" #API Key for OpenAI\n",
    "OPENAI_ENDPOINT = \"\" #Azure OpenAI Endpoint\n",
    "OPENAI_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": OPENAI_API_KEY,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the long pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf(input_pdf_path, output_pdf_paths, num_splits):\n",
    "    \"\"\"\n",
    "    Splits the input PDF into `num_splits` smaller PDFs.\n",
    "\n",
    "    :param input_pdf_path: Path to the input PDF file.\n",
    "    :param output_pdf_paths: List of paths for the output PDF files.\n",
    "    :param num_splits: Number of parts to split the PDF into.\n",
    "    :return: A list of tuples containing page ranges for each split file.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf_path)\n",
    "    total_pages = len(reader.pages)\n",
    "    pages_per_split = total_pages // num_splits\n",
    "    remainder = total_pages % num_splits\n",
    "\n",
    "    start_page = 0\n",
    "    page_ranges = []\n",
    "\n",
    "    for i in range(num_splits):\n",
    "        writer = PdfWriter()\n",
    "        end_page = start_page + pages_per_split + (1 if remainder > 0 else 0)\n",
    "        remainder = max(remainder - 1, 0)\n",
    "\n",
    "        for j in range(start_page, end_page):\n",
    "            writer.add_page(reader.pages[j])\n",
    "\n",
    "        with open(output_pdf_paths[i], \"wb\") as output_file:\n",
    "            writer.write(output_file)\n",
    "\n",
    "        page_ranges.append((start_page + 1, end_page))\n",
    "        start_page = end_page\n",
    "\n",
    "    print(f\"PDF successfully split into {output_pdf_paths}\")\n",
    "    return total_pages, page_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pdf_and_save_results(file_paths, output_markdown_paths):\n",
    "    \"\"\"\n",
    "    Analyzes each PDF file and saves the results to markdown files.\n",
    "\n",
    "    :param file_paths: List of paths to the PDF files to analyze.\n",
    "    :param output_markdown_paths: List of paths to save the markdown results.\n",
    "    \"\"\"\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=AZURE_ENDPOINT, credential=AzureKeyCredential(AZURE_KEY)\n",
    "    )\n",
    "    results = []\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            file_bytes = file.read()\n",
    "\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\",\n",
    "            AnalyzeDocumentRequest(bytes_source=file_bytes),\n",
    "            output_content_format=ContentFormat.MARKDOWN,\n",
    "        )\n",
    "        result = poller.result()\n",
    "\n",
    "        results.append(result.content)\n",
    "        with open(output_markdown_paths[i], \"w\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(result.content)\n",
    "\n",
    "        print(f\"Analysis result for file {file_path} saved to {output_markdown_paths[i]}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready for Azure Open AI Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_payload(document_content, question):\n",
    "    \"\"\"\n",
    "    Generate the payload for the OpenAI API request.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant analyzing a long document that has been split into multiple parts. Not all parts contain answers to the question, and if no part contains the answer, you should respond that no answers were found in the document.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"This is part of a long document split into smaller sections. Based on the following document content, help to answer the question: {question}\\n\\nDocument Content:\\n{document_content}\\n\\nIf the document does not contain the answer, respond with: 'Answers not found in this part.'\"\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 3000\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for Single Splited Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(file_path, question):\n",
    "    \"\"\"\n",
    "    Sends a request to the OpenAI API for a specific document part.\n",
    "\n",
    "    :param file_path: Path to the split document file.\n",
    "    :param question: The question to ask the document.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        document_content = file.read()\n",
    "\n",
    "    payload = generate_payload(document_content, question)\n",
    "    response = requests.post(OPENAI_ENDPOINT, headers=OPENAI_HEADERS, json=payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "\n",
    "    # Check if the response explicitly states no answer was found\n",
    "    answer = result['choices'][0]['message']['content']\n",
    "    if \"Answers not found in this part.\" in answer:\n",
    "        print(f\"No answers found in {file_path}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the anwsers for final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_responses(responses, question):\n",
    "    \"\"\"\n",
    "    Sends a final request to OpenAI to combine and summarize the responses.\n",
    "\n",
    "    :param responses: List of responses from the split documents.\n",
    "    :param question: The original question.\n",
    "    \"\"\"\n",
    "    combined_content = \"\\n\\n\".join(\n",
    "        [f\"Response from part {i + 1}:\\n{response['choices'][0]['message']['content']}\" for i, response in enumerate(responses)]\n",
    "    )\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant analyzing a long document that has been split into multiple parts. Not all parts contain answers to the question, and if no part contains the answer, you should respond that no answers were found in the document.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The following are responses from different parts of a split document. Combine these responses and provide a final answer to the question: {question}\\n\\n{combined_content}\\n\\nIf none of the parts contain the answer, respond with: 'No answers were found in the document.'\"\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 3000\n",
    "    }\n",
    "    response = requests.post(OPENAI_ENDPOINT, headers=OPENAI_HEADERS, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question to ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The question to ask\n",
    "QUESTION = \"Based on the document, help to answer the following question: What is personal data?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_pdf_path = \"CELEX_32016R0679_EN_TXT.pdf\"\n",
    "    NUM_SPLITS = 3\n",
    "    split_output_paths = [f\"split_part_{i + 1}.pdf\" for i in range(NUM_SPLITS)]\n",
    "    markdown_output_paths = [f\"split_part_{i + 1}.md\" for i in range(NUM_SPLITS)]\n",
    "\n",
    "    # Step 1: Split the PDF\n",
    "    total_pages, page_ranges = split_pdf(input_pdf_path, split_output_paths, NUM_SPLITS)\n",
    "\n",
    "    # Step 2: Analyze the split files\n",
    "    analyze_pdf_and_save_results(split_output_paths, markdown_output_paths)\n",
    "\n",
    "    # Step 3: Ask OpenAI for each split file\n",
    "    responses = []\n",
    "    for file_path in markdown_output_paths:\n",
    "        response = ask_openai(file_path, QUESTION)\n",
    "        responses.append(response)\n",
    "\n",
    "    # Step 4: Combine and summarize responses\n",
    "    final_response = combine_responses(responses, QUESTION)\n",
    "    final_answer = final_response['choices'][0]['message']['content']\n",
    "\n",
    "    # Output results\n",
    "    print(\"\\n--- Final Answer ---\")\n",
    "    print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
